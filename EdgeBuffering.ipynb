{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae35268-6b66-49ac-9bd0-30387458c762",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Python implementation of efficient edge recording\n",
    "\n",
    "## Background \n",
    "\n",
    "* Forward simulations still have trouble scaling\n",
    "* I showed how to parallelize simplification, but we are still\n",
    "  \"leaving performance on the table\" for the fundamental operations.\n",
    "* fwdpp has had a more efficient edge buffering method for over two years.\n",
    "* I presented it at one of the first tskit-dev meetings, but the feeling\n",
    "  was that it may be too specific (only applying to forward sims).\n",
    "  * I no longer agree -- the performance benefits are really big\n",
    "    and this type of sim is a core use for tskit-c.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "* I want to move fwdpy11 from using fwdpp's tables to tskit's.\n",
    "  * Reason: to output, we make a copy from fwdpp tables to tskit tables.\n",
    "    * In practice, we seem to always use less memory than SLiM, even\n",
    "      with this extra copy. However, this copying will bite us in the butt at some point\n",
    "      as simulations get larger and larger (N + total genetic map length).\n",
    "  * Reason 2: fwdpp has been a good testing ground for new ideas, but I can do\n",
    "    the same kinda experimentation more easily with my \"top secret\" [fwdpp replacement](https://github.com/ForwardSimulation/forrustts/)\n",
    "* We don't want to lose performance.\n",
    "* The barriers are:\n",
    "  * Sorting tables...\n",
    "  \n",
    "## Recent progress\n",
    "\n",
    "* Port the fwdpp edge buffer to tskit-rust.\n",
    "  * This is an open PR.\n",
    "  * The functionality is feature-gated.\n",
    "  * This PR gives the `buffering` results in the benchmark plots.\n",
    "  * Results are good, but arguably not great.\n",
    "  * Recording API is inelegant due to inner workings of simplification:\n",
    "    * The edge table validation uses stricter criteria than what \n",
    "      the algorithm requires.\n",
    "    * The buffering API needs to do extra steps to buffer segments by \n",
    "      child. In practice, hashing seems the best way to do this, making\n",
    "      it difficult to port back to C.\n",
    "    * We also need to bulk copy from the buffer to the tables prior to simplification.\n",
    "      This copying is unnecessary, inelegant, and hurts performance.\n",
    "* Stack a PR on top of the one described above.\n",
    "  * This PR must never be merged into tskit-rust.\n",
    "  * Add functionality to the C API to allow manual control over the simplification\n",
    "    steps.\n",
    "  * These tskit-c changes allow us to avoid all the API ugliness described above.\n",
    "  * **None of the internal tskit-c simplification machinery gets leaked due to applying the \"PIMPL idiom\"**\n",
    "  * This PR gives the `buffering_streaming` benchmark results.\n",
    "  * Full disclosure: this PR is not fully optimised. \n",
    "    It does too much work, has at least one allocation during simplification that can be removed, etc.. \n",
    "    Stacking it on the previous PR and then hacking led to some sub-optimal design re:the edge buffers inner workings.\n",
    "    \n",
    "### Limitations of the rust prototype\n",
    "\n",
    "1. As simulation epochs get longer, we retain performance benefits but memory savings are not as good.\n",
    "   This behavior is due to the capacity doubling behavior of `Vec`.\n",
    "   It is easy to change this:\n",
    "   * Allow a `max_capacity_increase` field.\n",
    "   * Allow capacity doubling until a doubling is a larger than `max_capacity_increase`, at which\n",
    "     point we rely on [Vec::reserve_exact](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.reserve_exact)\n",
    "     prior to any calls to `push`.\n",
    "   * We can play analagos games in `tskit-c` with `realloc`.\n",
    "   \n",
    "### Example of running the rust prototype\n",
    "\n",
    "The following code will run the edge buffer + modular simplification methods.\n",
    "\n",
    "```sh\n",
    "gh repo clone tskit-dev/tskit-rust\n",
    "cd tskit-rust\n",
    "gh pr checkout 443\n",
    "cargo build --release --examples --feature edgebuffer\n",
    "```\n",
    "\n",
    "Run this script, `run.sh`:\n",
    "                                           \n",
    "```sh\n",
    "#!/bin/sh\n",
    "\n",
    "ARGS=\"666 25000 250000 100\"\n",
    "\n",
    "/usr/bin/time -f \"%e %M\" -o old.time ./target/release/examples/haploid_wright_fisher -b $ARGS old.trees &\n",
    "/usr/bin/time -f \"%e %M\" -o old_nobookmark.time ./target/release/examples/haploid_wright_fisher $ARGS old_nobookmark.trees &\n",
    "/usr/bin/time -f \"%e %M\" -o new.time ./target/release/examples/haploid_wright_fisher_edge_buffering $ARGS new.trees                                           \n",
    "```\n",
    "\n",
    "When it returns, run `compare.py`:\n",
    "\n",
    "```python\n",
    "import tskit\n",
    "\n",
    "old = tskit.load(\"old.trees\")\n",
    "old_nobookmark = tskit.load(\"old_nobookmark.trees\")\n",
    "new = tskit.load(\"new.trees\")\n",
    "\n",
    "assert old_nobookmark.num_trees == old.num_trees\n",
    "assert old_nobookmark.num_nodes == old.num_nodes\n",
    "assert old_nobookmark.num_edges == old.num_edges\n",
    "assert old.num_trees == new.num_trees\n",
    "assert old.num_nodes == new.num_nodes\n",
    "assert old.num_edges == new.num_edges\n",
    "\n",
    "# We cannot use KC distance because:\n",
    "# 1. We get OOM error with tree seqs this large.\n",
    "# 2. Not all of the trees will have exactly 1 root.\n",
    "for i, j, k in zip(old.trees(), old_nobookmark.trees(), new.trees()):\n",
    "    assert i.span == j.span\n",
    "    assert i.total_branch_length == j.total_branch_length\n",
    "    assert i.span == k.span\n",
    "    assert i.total_branch_length == k.total_branch_length\n",
    "```\n",
    "\n",
    "Pro tip: the Python script takes ages.\n",
    "The asserts all pass.\n",
    "\n",
    "## Benchmark results from tskit-rust\n",
    "\n",
    "These were obtained on an AMD 5950x with 128GB DDR4 3600MT memory.\n",
    "I ran one at a time, with nothing else of note happening on the machine.\n",
    "\n",
    "For each `N`, simulations ran for `10N` non-overlapping generations.\n",
    "We are using the `tskit-rust` version of the `tskit-c` haploid Wright-Fisher example program.\n",
    "\n",
    "### Run time -- absolute\n",
    "\n",
    "![](benchmark_time.png)\n",
    "\n",
    "### Peak memory use -- absolute\n",
    "\n",
    "![](benchmark_mem.png)\n",
    "\n",
    "### Run time -- relative to the bookmark method\n",
    "\n",
    "![](benchmark_time_rel.png)\n",
    "\n",
    "### Run time -- delta from the bookmark method\n",
    "\n",
    "![](benchmark_time_delta.png)\n",
    "\n",
    "### Peak memory use -- relative to the bookmark method\n",
    "\n",
    "![](benchmark_mem_rel.png)\n",
    "\n",
    "### Peak memory use -- delta from the bookmark method\n",
    "\n",
    "![](benchmark_mem_delta.png)\n",
    "\n",
    "## The Python prototype\n",
    "\n",
    "The code below is a Python prototype that does everything except one step that is needed to correctly handle non-overlapping generations.\n",
    "That step is described in words at the bottom of this notebook.\n",
    "\n",
    "import tskit\n",
    "import numpy as np\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0e4d5-44be-4acb-a0de-9240bcce56d3",
   "metadata": {},
   "source": [
    "class Segment(object):\n",
    "    def __init__(self, left, right):\n",
    "        assert left < right, f\"{left} must be < {right}\"\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Segment({self.left}, {self.right})\"\n",
    "        \n",
    "class EdgeBuffer(object):\n",
    "    def __init__(self):\n",
    "        # Our linked lists managers\n",
    "        self.head = [] # i-th value records the start of data for parent i.\n",
    "        self.tail = []\n",
    "        self.next = []\n",
    "        # Our data\n",
    "        self.left = []\n",
    "        self.right = []\n",
    "        self.child = []\n",
    "        # helpers\n",
    "        self.collected_children = dict()\n",
    "        self.children = []\n",
    "        \n",
    "    def _clear(self):\n",
    "        \"\"\"\n",
    "        Free up memory\n",
    "        \"\"\"\n",
    "        self.head = []\n",
    "        self.tail = []\n",
    "        self.next = []\n",
    "        self.left = []\n",
    "        self.right = []\n",
    "        self.child = []\n",
    "        self.collected_children = dict()\n",
    "        self.children = []\n",
    "        \n",
    "    def _buffer_edge(self, left, right, parent, child):\n",
    "        if parent >= len(self.head):\n",
    "            self.head.extend([-1]*(parent-len(self.head)+1))\n",
    "            self.tail.extend([-1]*(parent-len(self.tail)+1))\n",
    "            assert parent + 1 == len(self.head), f\"{parent}, {len(self.head)}\"\n",
    "            assert parent + 1 == len(self.tail), f\"{parent}, {len(self.tail)}\"\n",
    "            \n",
    "        assert parent < len(self.head), f\"{parent} {len(self.head)}\"\n",
    "        assert parent < len(self.tail), f\"{parent} {len(self.tail)}\"\n",
    "\n",
    "        if self.head[parent] == -1:\n",
    "            self._insert_new_parent(left, right, parent, child)\n",
    "        else:\n",
    "            self._extend_parent(left, right, parent, child)\n",
    "            \n",
    "    def _update_data(self, left, right, child):\n",
    "        self.left.append(left)\n",
    "        self.right.append(right)\n",
    "        self.child.append(child)\n",
    "        \n",
    "    def _insert_new_parent(self, left, right, parent, child):\n",
    "        self._update_data(left, right, child)\n",
    "        self.head[parent] = len(self.left) - 1\n",
    "        self.tail[parent] = self.head[parent]\n",
    "        self.next.append(-1)\n",
    "    \n",
    "    def _extend_parent(self, left, right, parent, child):\n",
    "        self._update_data(left, right, child)\n",
    "        temp = self.tail[parent]\n",
    "        self.tail[parent] = len(self.left) - 1\n",
    "        self.next[temp] = len(self.left) - 1\n",
    "        self.next.append(-1)\n",
    "        \n",
    "    # Can skip right to _buffer_edge w/modular simplification API\n",
    "    def record_edge(self, left, right, parent, child):\n",
    "        self.collected_children[parent][child].append(Segment(left, right))\n",
    "    \n",
    "    # Not necessary w/modular simplification API\n",
    "    def init_recording_offspring(self, parents, children):\n",
    "        self.children = sorted([i for i in set([j for j in children])])\n",
    "        self.collected_children = dict()\n",
    "        for p in parents:\n",
    "            self.collected_children[p] = {c: [] for c in self.children}\n",
    "    \n",
    "    # Not necessary w/modular simplification API\n",
    "    def finalize_recording_offspring(self):\n",
    "        for p, edges in self.collected_children.items():\n",
    "            for c in self.children:\n",
    "                for e in edges[c]:\n",
    "                    assert e.left < e.right\n",
    "                    self._buffer_edge(e.left, e.right, p, c)\n",
    "\n",
    "    # This implementation suffices for non-overlapping\n",
    "    # generations and for overlapping generations.\n",
    "    # However, this type is not ready for overlapping\n",
    "    # generations -- see comments at end of notebook.\n",
    "    # Notes:\n",
    "    # * In C, this is done more efficiently by\n",
    "    #   appending edge tables rows and then\n",
    "    #   doing a \"left rotation\" of each column\n",
    "    #   when done.\n",
    "    def prep_for_simplification(self, tables):\n",
    "        left = []\n",
    "        right = []\n",
    "        parent = []\n",
    "        child = []\n",
    "        \n",
    "        # NOTE: this sorting exists because simplification can scramble\n",
    "        # the relationship between node it and birth time for non-overlapping\n",
    "        # generations.\n",
    "        # This sort is much less expensive than the current sorting approaches!\n",
    "        sorted_head_index = sorted([i for i in range(len(self.head)) if self.head[i] != -1],\n",
    "                             key = lambda x: tables.nodes.time[x])\n",
    "\n",
    "        # Go backwards in time through new edges\n",
    "        for parentid in sorted_head_index:\n",
    "            h = self.head[parentid]\n",
    "            left.append(self.left[h])\n",
    "            right.append(self.right[h])\n",
    "            parent.append(parentid)\n",
    "            child.append(self.child[h])\n",
    "\n",
    "            next = self.next[h]\n",
    "            while next != -1:\n",
    "                left.append(self.left[next])\n",
    "                right.append(self.right[next])\n",
    "                parent.append(parentid)\n",
    "                child.append(self.child[next])\n",
    "                next = self.next[next]\n",
    "                    \n",
    "        assert len(left) == len(right)\n",
    "        assert len(left) == len(parent)\n",
    "        assert len(left) == len(child)\n",
    "\n",
    "        # Append ancient edges\n",
    "        left.extend(tables.edges.left.tolist())\n",
    "        right.extend(tables.edges.right.tolist())\n",
    "        parent.extend(tables.edges.parent.tolist())\n",
    "        child.extend(tables.edges.child.tolist())\n",
    "        \n",
    "        assert len(left) == len(right)\n",
    "        assert len(left) == len(parent)\n",
    "        assert len(left) == len(child)\n",
    "        \n",
    "        # Set columns\n",
    "        tables.edges.set_columns(left=left, right=right,\n",
    "                                 parent=np.array(parent, dtype=np.int32),\n",
    "                                 child=np.array(child, dtype=np.int32))\n",
    "        assert tables.edges.num_rows > 0 # technically a bad idea\n",
    "        \n",
    "        # Free memory prior to simplifying\n",
    "        self._clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1992bea-8075-4b6c-aae6-3b995bcfb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haploid sim w/exactly one crossover per offspring\n",
    "def overlapping_generations(seed, popsize, nsteps, simplify, pdeath=1.0):\n",
    "    assert pdeath == 1.0, \"The buffer is not generalized to overlapping generations yet\"\n",
    "    assert pdeath > 0.0 and pdeath <= 1.0\n",
    "    L = 10\n",
    "    tables = tskit.TableCollection(L)\n",
    "    buffer = EdgeBuffer()\n",
    "    birth_time = nsteps\n",
    "    parents = []\n",
    "    np.random.seed(seed)\n",
    "    for _ in range(popsize):\n",
    "        n = tables.nodes.add_row(0, birth_time)\n",
    "        parents.append(n)\n",
    "        \n",
    "    for t in range(birth_time-1, -1, -1):\n",
    "        deaths = []\n",
    "        for i in range(len(parents)):\n",
    "            if np.random.sample(1) <= pdeath:\n",
    "                deaths.append(i)\n",
    "        births = []\n",
    "        for _ in range(len(deaths)):\n",
    "            p1 = np.random.choice(parents, 1)[0]\n",
    "            p2 = np.random.choice(parents, 1)[0]\n",
    "            c = tables.nodes.add_row(0, t)\n",
    "            births.append(c)\n",
    "            breakpoint = np.random.randint(1, L, 1)[0]\n",
    "            current_parents = [p1, p2]\n",
    "            children = [c]\n",
    "            buffer.init_recording_offspring(current_parents, children) # only needed b/c of current tskit requirements\n",
    "            buffer.record_edge(0, breakpoint, p1, c)\n",
    "            buffer.record_edge(breakpoint, L, p2, c)\n",
    "            buffer.finalize_recording_offspring() # only needed b/c of current tskit requirements\n",
    "\n",
    "        assert len(births) == len(parents)\n",
    "        for i,d in enumerate(deaths):\n",
    "            parents[d] = births[i]\n",
    "\n",
    "        if t % simplify == 0:\n",
    "            assert all(tables.nodes.time[i] == t for i in parents) # non-overlapping gens only!\n",
    "            # OMG we are not calling table sort here!!!!\n",
    "            buffer.prep_for_simplification(tables)\n",
    "            idmap = tables.simplify(samples=parents)\n",
    "            for i in range(len(parents)):\n",
    "                assert idmap[parents[i]] != -1\n",
    "                parents[i] = idmap[parents[i]]\n",
    "              \n",
    "    return tables.tree_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed70e9f-2c84-4083-a1ee-23e5aad0e99a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tskit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ts \u001b[38;5;241m=\u001b[39m \u001b[43moverlapping_generations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m, in \u001b[0;36moverlapping_generations\u001b[0;34m(seed, popsize, nsteps, simplify, pdeath)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pdeath \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pdeath \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m      5\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 6\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mtskit\u001b[49m\u001b[38;5;241m.\u001b[39mTableCollection(L)\n\u001b[1;32m      7\u001b[0m buffer \u001b[38;5;241m=\u001b[39m EdgeBuffer()\n\u001b[1;32m      8\u001b[0m birth_time \u001b[38;5;241m=\u001b[39m nsteps\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tskit' is not defined"
     ]
    }
   ],
   "source": [
    "ts = overlapping_generations(42, 5, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694d870-254e-4ef6-a213-dea3571f723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(ts.draw_svg())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40684621-e42d-45df-a405-9f7534da829c",
   "metadata": {},
   "source": [
    "# What we really want to do\n",
    "\n",
    "* Skip the bulk movement of data from edge buffer to edge table.\n",
    "* Have a simplification API where client code can control the steps.\n",
    "* This is \"power user mode\", but the payoff is performance.\n",
    "\n",
    "Let's look at some pseudocode:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2ddcd9-e589-484e-8c05-bec96f2842c2",
   "metadata": {},
   "source": [
    "```rust\n",
    "// We will look at the behind-the-scenes of this next.\n",
    "let mut simplifier = ModularSimplifier::new(samples, options, &mut tables);\n",
    "\n",
    "// Process the most recent births\n",
    "for h in edge_buffer.iter_backwards_in_time() {\n",
    "    for (left, right, parent, child) in edge_buffer.get_edges(h) {\n",
    "        // runs \"extract ancestry\"\n",
    "        simplifier.enqueue_edge(left, right, parent, child);\n",
    "    }\n",
    "    // runs \"merge ancestors\", resets internal queue size to 0\n",
    "    simplifier.merge_ancestors();\n",
    "}\n",
    "\n",
    "// Process the ancient edges\n",
    "// simplifier.process_input_edges();\n",
    "let input_edges = simplifier.input_edge_table_reference();\n",
    "let mut i = 0;\n",
    "while i < input_edges.num_rows() {\n",
    "    let p = input_edges.parent(i);\n",
    "    while i < input_edges.num_rows() && input_edges.parent(i) == p {\n",
    "        simplifier.enqueue_edge(left, right, parent, child);\n",
    "        i += 1;\n",
    "    }\n",
    "    simplifier.merge_ancestors();\n",
    "}\n",
    "\n",
    "// The final cleanup steps that occur at the end of the current\n",
    "// simplifier_run() function\n",
    "simplifier.finalise();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3b653-343d-407a-9fab-d6b3b83428d1",
   "metadata": {},
   "source": [
    "For a variety of reasons, the above is not strictly possible. \n",
    "(At least not right now.)\n",
    "However, I do have its functional equivalent working, albeit crudely.\n",
    "\n",
    "This \"modular\" simplification allows you to:\n",
    "\n",
    "* skip collecting newborn edges by child id.\n",
    "* doing big pointless transfers of big arrays\n",
    "\n",
    "For overlapping generations, the buffer needs to:\n",
    "\n",
    "* Be fed the maximum time of nodes live during the last simplification.\n",
    "* Take this time and go over the edge table, inserting all edges for which `time[parent]` is <= `max_time`.\n",
    "* Record the last edge index from the last step.\n",
    "* Left-rotate the columns at this index and truncate the edge table.\n",
    "\n",
    "These steps must be done at the START of a recording epoch so that your final simplification at the end of a sim doesn't steal edges from the edge table.\n",
    "\n",
    "## TODO list for PRs\n",
    "\n",
    "* Extract final simplification steps to new static function. **NOT NECESSARY ANY LONGER--FINALISE CAN HANDLE ALL OF THIS.**\n",
    "* Implement modular simpifier\n",
    "  * Tests: we should get same outputs as the regular method.\n",
    "* Implement `tsk_edge_buffer_t`\n",
    "  * This would get people to use it.\n",
    "  * The down side is that most folks will stop there, possibly halting innovations.\n",
    "  * I think it is important to not just implement this w/o a public \"modular simplifier\".\n",
    "    * There may be other clever uses of fine-grained control over simplification steps.\n",
    "* Document and/or example program."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
